{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7e3eb5",
   "metadata": {},
   "source": [
    "# Chest X‑Ray Classification (Pneumonia vs Normal) — Flexible Backbone\n",
    "\n",
    "This notebook classifies **Pneumonia vs Normal chest X‑rays** using transfer learning.  \n",
    "It supports **multiple pretrained backbones** so you can balance accuracy vs speed:\n",
    "\n",
    "- `MobileNetV2` → lightweight, fastest on CPU.  \n",
    "- `ResNet50` → stronger, slower on CPU.  \n",
    "- `EfficientNetB3` → good balance of accuracy and efficiency.\n",
    "\n",
    "Change the `BACKBONE` variable to switch between them.\n",
    "\n",
    "> ⚠️ Educational use only — not for clinical diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30031e",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157ad81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.18.0\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298265ac",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa5c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone: EfficientNetB3 | Input size: (300, 300)\n",
      "Model path: C:\\\\CAS AML\\\\project M1 and M2\\\\Chest X Rays v4\\pneumonia_xray_EfficientNetB3.keras\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#DATASET_ROOT = \"/content/drive/MyDrive/chest_xrays_v4\"\n",
    "\n",
    "DATASET_ROOT = r\"C:\\\\CAS AML\\\\project M1 and M2\\\\Chest X Rays v4\"  # change if needed\n",
    "\n",
    "\n",
    "BACKBONE = \"MobileNetV2\" #EfficientNetB3\"  or \"MobileNetV2\", \"ResNet50\"\n",
    "\n",
    "if BACKBONE == \"MobileNetV2\":\n",
    "    IMG_SIZE = (224, 224)\n",
    "elif BACKBONE == \"ResNet50\":\n",
    "    IMG_SIZE = (224, 224)\n",
    "elif BACKBONE == \"EfficientNetB3\":\n",
    "    IMG_SIZE = (300, 300)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported backbone\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SEED = 123\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "MODEL_PATH = os.path.join(DATASET_ROOT, f\"pneumonia_xray_{BACKBONE}.keras\")\n",
    "\n",
    "print(\"Backbone:\", BACKBONE, \"| Input size:\", IMG_SIZE)\n",
    "print(\"Model path:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491597c",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f0f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12229 files belonging to 2 classes.\n",
      "Found 1165 files belonging to 2 classes.\n",
      "Found 582 files belonging to 2 classes.\n",
      "Classes: ['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(DATASET_ROOT, \"train\")\n",
    "val_dir   = os.path.join(DATASET_ROOT, \"valid\")\n",
    "test_dir  = os.path.join(DATASET_ROOT, \"test\")\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(train_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED)\n",
    "val_ds   = tf.keras.utils.image_dataset_from_directory(val_dir,   image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED)\n",
    "test_ds  = tf.keras.utils.image_dataset_from_directory(test_dir,  image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f5e47",
   "metadata": {},
   "source": [
    "## 4. Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf37d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "def prep(ds, training=False):\n",
    "    ds = ds.map(lambda x,y:(normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(lambda x,y:(data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds_prep = prep(train_ds, training=True)\n",
    "val_ds_prep   = prep(val_ds, training=False)\n",
    "test_ds_prep  = prep(test_ds, training=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231eaa5",
   "metadata": {},
   "source": [
    "## 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f23c076a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,074</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb3 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m1536\u001b[0m)   │    \u001b[38;5;34m10,783,535\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m3,074\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,786,609</span> (41.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,786,609\u001b[0m (41.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,074</span> (12.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,074\u001b[0m (12.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,783,535</span> (41.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10,783,535\u001b[0m (41.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(backbone):\n",
    "    if backbone == \"MobileNetV2\":\n",
    "        base = keras.applications.MobileNetV2(input_shape=IMG_SIZE+(3,), include_top=False, weights=\"imagenet\")\n",
    "        preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
    "    elif backbone == \"ResNet50\":\n",
    "        base = keras.applications.ResNet50(input_shape=IMG_SIZE+(3,), include_top=False, weights=\"imagenet\")\n",
    "        preprocess_input = keras.applications.resnet50.preprocess_input\n",
    "    elif backbone == \"EfficientNetB3\":\n",
    "        base = keras.applications.EfficientNetB3(input_shape=IMG_SIZE+(3,), include_top=False, weights=\"imagenet\")\n",
    "        preprocess_input = keras.applications.efficientnet.preprocess_input\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone\")\n",
    "    base.trainable = False\n",
    "    inputs = keras.Input(shape=IMG_SIZE+(3,))\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model = build_model(BACKBONE)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703858c",
   "metadata": {},
   "source": [
    "## 6. Compile & Train/Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fad599",
   "metadata": {},
   "source": [
    "## Training with Callbacks (EarlyStopping + ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72924536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_PATH, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1\n",
    ")\n",
    "earlystop_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# Train with callbacks\n",
    "history = model.fit(\n",
    "    train_ds_prep,\n",
    "    validation_data=val_ds_prep,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb]\n",
    ")\n",
    "\n",
    "print(\"Best model saved at:\", MODEL_PATH)\n",
    "\n",
    "# --- Plot training history ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history.get(\"accuracy\", [])\n",
    "val_acc = history.history.get(\"val_accuracy\", [])\n",
    "loss = history.history.get(\"loss\", [])\n",
    "val_loss = history.history.get(\"val_loss\", [])\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc, label=\"Train Acc\")\n",
    "plt.plot(val_acc, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "plt.title(\"Loss over Epochs\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb61ce72",
   "metadata": {},
   "source": [
    "## 7. Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa4946",
   "metadata": {},
   "source": [
    "## Training with Callbacks (EarlyStopping + ModelCheckpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7beb21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    MODEL_PATH, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1\n",
    ")\n",
    "earlystop_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=5, restore_best_weights=True, verbose=1\n",
    ")\n",
    "\n",
    "# Train with callbacks\n",
    "history = model.fit(\n",
    "    train_ds_prep,\n",
    "    validation_data=val_ds_prep,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint_cb, earlystop_cb]\n",
    ")\n",
    "\n",
    "print(\"Best model saved at:\", MODEL_PATH)\n",
    "\n",
    "# --- Plot training history ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history.get(\"accuracy\", [])\n",
    "val_acc = history.history.get(\"val_accuracy\", [])\n",
    "loss = history.history.get(\"loss\", [])\n",
    "val_loss = history.history.get(\"val_loss\", [])\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(acc, label=\"Train Acc\")\n",
    "plt.plot(val_acc, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend()\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(loss, label=\"Train Loss\")\n",
    "plt.plot(val_loss, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "plt.title(\"Loss over Epochs\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202ae5f",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24db7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(test_ds_prep, verbose=0)\n",
    "print(\"Test metrics:\", dict(zip(model.metrics_names, test_results)))\n",
    "\n",
    "y_true, y_prob = [], []\n",
    "for images, labels in test_ds_prep:\n",
    "    probs = model.predict(images, verbose=0)\n",
    "    y_prob.extend(probs); y_true.extend(labels.numpy())\n",
    "y_true = np.array(y_true); y_prob = np.array(y_prob)\n",
    "y_pred = y_prob.argmax(axis=1)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true,y_pred))\n",
    "print(classification_report(y_true,y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "pos_label = 1 if \"pneumonia\" in class_names[1].lower() else 0\n",
    "auc = roc_auc_score((y_true==pos_label).astype(int), y_prob[:,pos_label])\n",
    "print(\"ROC-AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bfbca",
   "metadata": {},
   "source": [
    "## 9. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_ds.take(1):\n",
    "    probs = model.predict(images, verbose=0)\n",
    "    preds = probs.argmax(axis=1)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(min(8, images.shape[0])):\n",
    "        ax = plt.subplot(2,4,i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        p, t = class_names[preds[i]], class_names[labels[i].numpy()]\n",
    "        plt.title(f\"Pred: {p}\\nTrue: {t}\"); plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

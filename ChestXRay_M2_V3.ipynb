{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a7e3eb5",
   "metadata": {},
   "source": [
    "# Chest X‑Ray Classification (Pneumonia vs Normal) — Flexible Backbone\n",
    "\n",
    "This notebook classifies **Pneumonia vs Normal chest X‑rays** using transfer learning.  \n",
    "It supports **multiple pretrained backbones** so you can balance accuracy vs speed:\n",
    "\n",
    "- `MobileNetV2` → lightweight, fastest on CPU.  \n",
    "- `ResNet50` → stronger, slower on CPU.  \n",
    "- `EfficientNetB3` → good balance of accuracy and efficiency.\n",
    "\n",
    "Change the `BACKBONE` variable to switch between them.\n",
    "\n",
    "> ⚠️ Educational use only — not for clinical diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30031e",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ad81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298265ac",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa5c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/content/drive/MyDrive/datasets/chest_xrays_v4\"\n",
    "BACKBONE = \"EfficientNetB3\"  # or \"MobileNetV2\", \"ResNet50\"\n",
    "\n",
    "if BACKBONE == \"MobileNetV2\":\n",
    "    IMG_SIZE = (224, 224)\n",
    "elif BACKBONE == \"ResNet50\":\n",
    "    IMG_SIZE = (224, 224)\n",
    "elif BACKBONE == \"EfficientNetB3\":\n",
    "    IMG_SIZE = (300, 300)\n",
    "else:\n",
    "    raise ValueError(\"Unsupported backbone\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "SEED = 123\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "MODEL_PATH = os.path.join(DATASET_ROOT, f\"pneumonia_xray_{BACKBONE}.keras\")\n",
    "\n",
    "print(\"Backbone:\", BACKBONE, \"| Input size:\", IMG_SIZE)\n",
    "print(\"Model path:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491597c",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(DATASET_ROOT, \"train\")\n",
    "val_dir   = os.path.join(DATASET_ROOT, \"valid\")\n",
    "test_dir  = os.path.join(DATASET_ROOT, \"test\")\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(train_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED)\n",
    "val_ds   = tf.keras.utils.image_dataset_from_directory(val_dir,   image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED)\n",
    "test_ds  = tf.keras.utils.image_dataset_from_directory(test_dir,  image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED)\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f5e47",
   "metadata": {},
   "source": [
    "## 4. Preprocessing & Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.15),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "def prep(ds, training=False):\n",
    "    ds = ds.map(lambda x,y:(normalization_layer(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        ds = ds.map(lambda x,y:(data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds_prep = prep(train_ds, training=True)\n",
    "val_ds_prep   = prep(val_ds, training=False)\n",
    "test_ds_prep  = prep(test_ds, training=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231eaa5",
   "metadata": {},
   "source": [
    "## 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(backbone):\n",
    "    if backbone == \"MobileNetV2\":\n",
    "        base = keras.applications.MobileNetV2(input_shape=IMG_SIZE+(3,), include_top=False, weights=\"imagenet\")\n",
    "        preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
    "    elif backbone == \"ResNet50\":\n",
    "        base = keras.applications.ResNet50(input_shape=IMG_SIZE+(3,), include_top=False, weights=\"imagenet\")\n",
    "        preprocess_input = keras.applications.resnet50.preprocess_input\n",
    "    elif backbone == \"EfficientNetB3\":\n",
    "        base = keras.applications.EfficientNetB3(input_shape=IMG_SIZE+(3,), include_top=False, weights=\"imagenet\")\n",
    "        preprocess_input = keras.applications.efficientnet.preprocess_input\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported backbone\")\n",
    "    base.trainable = False\n",
    "    inputs = keras.Input(shape=IMG_SIZE+(3,))\n",
    "    x = preprocess_input(inputs)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "model = build_model(BACKBONE)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703858c",
   "metadata": {},
   "source": [
    "## 6. Compile & Train/Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0da173",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "if pathlib.Path(MODEL_PATH).exists():\n",
    "    print(\"Loading pretrained:\", MODEL_PATH)\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "else:\n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor=\"val_accuracy\"),\n",
    "        keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    ]\n",
    "    history = model.fit(train_ds_prep, validation_data=val_ds_prep, epochs=15, callbacks=callbacks)\n",
    "    model.save(MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb61ce72",
   "metadata": {},
   "source": [
    "## 7. Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3000732",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[-50:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history_ft = model.fit(train_ds_prep, validation_data=val_ds_prep, epochs=5)\n",
    "model.save(MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1202ae5f",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24db7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(test_ds_prep, verbose=0)\n",
    "print(\"Test metrics:\", dict(zip(model.metrics_names, test_results)))\n",
    "\n",
    "y_true, y_prob = [], []\n",
    "for images, labels in test_ds_prep:\n",
    "    probs = model.predict(images, verbose=0)\n",
    "    y_prob.extend(probs); y_true.extend(labels.numpy())\n",
    "y_true = np.array(y_true); y_prob = np.array(y_prob)\n",
    "y_pred = y_prob.argmax(axis=1)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true,y_pred))\n",
    "print(classification_report(y_true,y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "pos_label = 1 if \"pneumonia\" in class_names[1].lower() else 0\n",
    "auc = roc_auc_score((y_true==pos_label).astype(int), y_prob[:,pos_label])\n",
    "print(\"ROC-AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bfbca",
   "metadata": {},
   "source": [
    "## 9. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_ds.take(1):\n",
    "    probs = model.predict(images, verbose=0)\n",
    "    preds = probs.argmax(axis=1)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(min(8, images.shape[0])):\n",
    "        ax = plt.subplot(2,4,i+1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        p, t = class_names[preds[i]], class_names[labels[i].numpy()]\n",
    "        plt.title(f\"Pred: {p}\\nTrue: {t}\"); plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
